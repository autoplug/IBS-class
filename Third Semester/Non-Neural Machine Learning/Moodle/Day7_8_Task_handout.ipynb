{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRAiadZiNqds"
      },
      "source": [
        "# The dataset\n",
        "\n",
        "<img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\">\n",
        "\n",
        "\n",
        "(Image source: [www.tensorflow.org](https://www.tensorflow.org/tutorials/keras/basic_classification))\n",
        "\n",
        "Today's dataset is [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) -- a drop-in replacement for MNIST but with clothing items instead of digits. The categories are\n",
        "\n",
        "+ 0 -- \tT-shirt/top\n",
        "+ 1 -- \tTrouser\n",
        "+ 2 -- \tPullover\n",
        "+ 3 -- \tDress\n",
        "+ 4 -- \tCoat\n",
        "+ 5 -- \tSandal\n",
        "+ 6 -- \tShirt\n",
        "+ 7 -- \tSneaker\n",
        "+ 8 -- \tBag\n",
        "+ 9 --  Ankle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "h7Wpfpd-Nqdw"
      },
      "source": [
        "# Loading the dataset\n",
        "\n",
        "Just run the codes to get the data.\n",
        "\n",
        "* `images` will be the array with the image (\"input\") data\n",
        "* `labels` will be the array with the label (\"target\") data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgqJsTAZzEwE"
      },
      "outputs": [],
      "source": [
        "def load_mnist(path, kind='train'):\n",
        "    import os\n",
        "    import gzip\n",
        "    import numpy as np\n",
        "\n",
        "    \"\"\"Load MNIST data from `path`\"\"\"\n",
        "    labels_path = os.path.join(path,\n",
        "                               '%s-labels-idx1-ubyte.gz'\n",
        "                               % kind)\n",
        "    images_path = os.path.join(path,\n",
        "                               '%s-images-idx3-ubyte.gz'\n",
        "                               % kind)\n",
        "\n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
        "                               offset=8)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                               offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iQjRHty0Nqdw"
      },
      "outputs": [],
      "source": [
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(12) #This is good practice for reproducibiity\n",
        "    \n",
        "images, labels = load_mnist(\".\")\n",
        "\n",
        "images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1BBnWStTNqdx"
      },
      "outputs": [],
      "source": [
        "labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpgFv8ujNqdy"
      },
      "source": [
        "## Task: Look at the images!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NWWiELMINqdy"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# First  get and reshape the  _first_ image of the images data to the visible 28x28 shape\n",
        "# (Hint, image is a numpy.ndarray, it has a function for that...)\n",
        "\n",
        "# Show the image using pyplot.imshow\n",
        "# Colormap should be \"Greys\"\n",
        "\n",
        "\n",
        "reshaped_image =...\n",
        "...\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WSqnWx4Nqdy"
      },
      "source": [
        "## Not task: just look at the first 30 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "s-nPcmjENqdz"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "\n",
        "def show_images(images):\n",
        "    \"\"\"Show images in a grid\n",
        "    \"\"\"\n",
        "    n_rows = ceil(len(images) / 10)\n",
        "    fig, ax = plt.subplots(n_rows, 10, figsize=(15, 1.5 * n_rows),\n",
        "                           subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                           gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "    for i, _ in enumerate(images):\n",
        "        ax[i // 10, i % 10].imshow(images[i].reshape(28, 28), cmap='Greys')\n",
        "\n",
        "show_images(images[:30])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FIWKZ39kNqd0"
      },
      "outputs": [],
      "source": [
        "labels[:30]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn6Z60j3Nqd0"
      },
      "source": [
        "# Task: PCA\n",
        "\n",
        "We will use Principal Component Analysis of the dataset to come up with decomposed version of the dataset.\n",
        "\n",
        "During the PCA we first find the components, then we transform the original dataset in terms of the new components, which is called \"transform\" in Scikit's parlance, and results in a new representation of the original data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fgUAH0DtNqd0"
      },
      "outputs": [],
      "source": [
        "# Import and use principal components analysis from Scikit\n",
        "# generate enough components to explain more than 50% of the total variation\n",
        "# use the PCA model to transform the image data and store the transformed form in the variable below\n",
        "\n",
        "...\n",
        "\n",
        "pca = ... #This should be the model...\n",
        "    \n",
        "transformed = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qEygBEBENqd1"
      },
      "outputs": [],
      "source": [
        "## Nothing to do here, just run the code!\n",
        "\n",
        "# Check that the explained variance of the components matches the ones below. Hopefully, \"random seed\" works well for this. :-)\n",
        "variance_rate = pca.explained_variance_ratio_\n",
        "\n",
        "np.testing.assert_array_almost_equal(variance_rate, np.array([ 0.29039228,  0.1775531 ,  0.06019222]))\n",
        "# Small learning: np object's \"sameness\" cannot be asserted by python's default assert\n",
        "# and numeric precision problems prevent even np.assert_equal to be usable\n",
        "# we have to stick with the approach above. (default=6 decimals)\n",
        "\n",
        "variance_rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vn2dRXNNqd2"
      },
      "source": [
        "## Task: Back transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MoKjHUQGNqd2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Please transform \"back\" all the images with the help of the fitted pca object\n",
        "# Use the documentation of Scikit - and google ;-) \n",
        "# to find the appropriate single function of the PCA object!\n",
        "# Show the first 30 \"back transformed\" images here\n",
        "# You can use the displaying function we have written above to show the first 30 of them...\n",
        "\n",
        "...\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rRjFo1sNqd3"
      },
      "source": [
        "## Task: Observe the reconstructed images, let's discuss what we learn!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5kGjRPhNqd3"
      },
      "source": [
        "## Task: Analyze the components\n",
        "\n",
        "... And let us see the components!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PIbfg0UWNqd3"
      },
      "outputs": [],
      "source": [
        "# Construct the \"plot\" of the components!\n",
        "#\n",
        "# The method is: \n",
        "# 1. construct one synthetic image with exactly one component being \"strong\"\n",
        "# - ie. with a super high (arbitrary) numeric value in one component\n",
        "# and all other values 0 (yes, really, just put a biiig number of your choosing in there :-)\n",
        "# (for this you have to know how many components we have, and create an array of that shape)\n",
        "#\n",
        "# 2. Use \"back transform\" as above, and then \n",
        "#\n",
        "# 3. display the image with Pyplot and imshow\n",
        "# One separate plot per component is ok, but a complex plot with subplots is more desirable\n",
        "# https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplot.html - for bonus happiness ;-)\n",
        "\n",
        "...\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEieNV7eNqd4"
      },
      "source": [
        "And now a 2d and 3d visualisation with class labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9AfleyTDNqd4"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pylab\n",
        "\n",
        "categories = [\"T-shirt/top\",\n",
        "              \"Trouser\",\n",
        "              \"Pullover\",\n",
        "              \"Dress\",\n",
        "              \"Coat\",\n",
        "              \"Sandal\",\n",
        "              \"Shirt\",\n",
        "              \"Sneaker\",\n",
        "              \"Bag\",\n",
        "              \"Ankle boot\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5yH1zCjqNqd5"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(12, 9))\n",
        "\n",
        "# Plot the 2D scatterplot of _first two_ dimensions of the transformed_data\n",
        "# transformed data ideally you already have in a numpy array\n",
        "# you basically want to have \"all rows of the first column\" vs. \n",
        "# \"all rows of the second column\" as the variables of the scatterplot.\n",
        "# Since numpy arrays do not have a built in plotting as pandas DataFrames, you have to use \n",
        "# the scatterplot function from the imported pyplot - that is plt - namespace.\n",
        "# No hassle, it is already done.\n",
        "# Use the labels for coloring (argument c) and colormap \"tab10\" (argument cmap) - yes, just so, as a string. Because it's nice. :-)\n",
        "\n",
        "...\n",
        "\n",
        "cb = plt.colorbar()\n",
        "loc = np.arange(0.5,9.5,9/10)\n",
        "cb.set_ticks(loc)\n",
        "cb.set_ticklabels(categories)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bgKtMrVNqd5"
      },
      "source": [
        "## Task: Let's observe the distribution of the original images plotted at the positions defined by their PCA transformation!\n",
        "\n",
        "What can we learn from it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9AR4GWyfNqd5"
      },
      "outputs": [],
      "source": [
        "# Nothing to do here, just observe the results! (Will take some time to run.)\n",
        "\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "\n",
        "def visualize_scatter_with_images(coords, images, figsize=(45,45), image_zoom=3):\n",
        "    # From https://www.kaggle.com/gaborvecsei/plants-t-sne\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    for xy, i in zip(coords, images):\n",
        "        x0, y0 = xy\n",
        "        img = OffsetImage(i.reshape(28,28), zoom=image_zoom, cmap=\"Greys\")\n",
        "        ab = AnnotationBbox(img, (x0, y0), xycoords='data', frameon=False)\n",
        "        ax.add_artist(ab)\n",
        "    ax.update_datalim(coords)\n",
        "    ax.autoscale()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize_scatter_with_images(transformed[:10000,:2], images[:10000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gbv9xFDONqd6"
      },
      "source": [
        "## Task: Construct a 3D scatterplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_4hfGDjANqd6"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure(figsize=(12, 9))\n",
        "ax = Axes3D(fig, elev=-150, azim=30)\n",
        "\n",
        "# Use the \"eerily similar\" approach to above to construct a 3D scatterplot\n",
        "# Nearly exactly the same as the 2D scatterplot you did before, same data source...\n",
        "path = ax...\n",
        "\n",
        "\n",
        "cb = plt.colorbar(paths)\n",
        "loc = np.arange(0.5,9.5,9/10)\n",
        "cb.set_ticks(loc)\n",
        "cb.set_ticklabels(categories)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VISBa6-7Nqd7"
      },
      "source": [
        "# Task: NMF method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "En1yUweNNqd7"
      },
      "outputs": [],
      "source": [
        "# Import and use the non-negative matrix factorization function from Scikit\n",
        "# Use 3 components to represent the data\n",
        "# Plot the first 30 \"back transformed\" images\n",
        "# Heavily copy from the approaches above! Nothing new under the sun! :-)\n",
        "\n",
        "...\n",
        "\n",
        "nmf = ...\n",
        "\n",
        "transformed = ...\n",
        "\n",
        "...\n",
        "\n",
        "show_images(images_nmf[:30])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T1ZWdTmNqd7"
      },
      "source": [
        "## Task: Plot the components!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UihYFExyNqd7"
      },
      "outputs": [],
      "source": [
        "# Plot the three components as above!\n",
        "# Copy, copy, modify... Just to get used to what is what...\n",
        "\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U-OXjiXNqd8"
      },
      "source": [
        "## Task: Observe the behavior of NMF, let's discuss results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lb4VbtAXNqd8"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(12, 9))\n",
        "plt.scatter(transformed[:,1], transformed[:,2], c=labels, cmap=\"tab10\", s=4)\n",
        "\n",
        "cb = plt.colorbar()\n",
        "loc = np.arange(0.5,9.5,9/10)\n",
        "cb.set_ticks(loc)\n",
        "cb.set_ticklabels(categories)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SJIJghANqd8"
      },
      "source": [
        "**Observe, that everything is squeezed into the positive region - unsurprisingly.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Eb5ZvzjkNqd8"
      },
      "outputs": [],
      "source": [
        "#Please implement the 3D visualization of the transformed space as above!\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIL3OYTXNqd9"
      },
      "source": [
        "# t-SNE\n",
        "\n",
        "Because of the slowness of t-SNE we will work with a random sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_GRJMHtNqd9"
      },
      "source": [
        "## Task: create a random subset of the data - only with Numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IQXV1Ir1Nqd9"
      },
      "outputs": [],
      "source": [
        "# Create a subsample of the data\n",
        "# use Numpy's sampling methods - google + documentation / examples helps!\n",
        "# 5000 samples and no replacement\n",
        "# The way to solve this elegantly is to create a random index and use it for subsetting the labels and data\n",
        "\n",
        "n_sample = 5000\n",
        "\n",
        "sample_indexes = ... #hint, hint: numpy has something like \"choice\"\n",
        "\n",
        "images_sample = ... # an indexes variable can be used for subsetting _ROWS_!!! (NOT columns...)\n",
        "\n",
        "assert images_sample.shape == (5000, 784)\n",
        "\n",
        "images_sample.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xwN03ZjNqd9"
      },
      "source": [
        "## Task: fit t-SNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kML8ZjmRNqd9"
      },
      "outputs": [],
      "source": [
        "# Plese import and use Scikit's tsne\n",
        "# Run the fitting with the subsample of the data that you managed to create, called image_sample\n",
        "# It would be fun to do it with all, but would be rather slow.\n",
        "\n",
        "...\n",
        "\n",
        "images_tsne = ...\n",
        "\n",
        "# Please implement the scatterplot of the transformed data\n",
        "# use the labels for the sample indices\n",
        "# Please bear in mind that you don't need all the labels stored in the \"labels\" variable\n",
        "# for coloring, just the same subsample that you have created!\n",
        "# Re-use the index!\n",
        "# And be brave, use the subsetted labels as \"c\" value in the scatter function\n",
        "# use colormap \"tab10\"\n",
        "# https://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html\n",
        "\n",
        "...\n",
        "\n",
        "cb = plt.colorbar()\n",
        "loc = np.arange(0.5,9.5,9/10)\n",
        "cb.set_ticks(loc)\n",
        "cb.set_ticklabels(categories)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzXZWwhkNqd-"
      },
      "source": [
        "# Just some fun: we display the t-SNE results - No code task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8TM2WGXuNqd-",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "visualize_scatter_with_images(images_tsne, images[sample_indexes])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mvpz7RKBNqd_"
      },
      "source": [
        "## Task: Please observe the distribution of the images!\n",
        "\n",
        "**What are some interesting learnings?**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "165px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
