{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Alireza Bolhassani***\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading and Initial Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the groundtruth data and participants consisit of 2909 row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad_clicked</th>\n",
       "      <th>log_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20181002033126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20181001211223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>20181001170952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ad_clicked          log_id\n",
       "0           0  20181002033126\n",
       "1           1  20181001211223\n",
       "2           0  20181001170952"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataframe in pandas format\n",
    "import pandas as pd\n",
    "\n",
    "groundtruth = pd.read_csv(\"groundtruth.tsv\", delimiter=\"\\t\")\n",
    "groundtruth = groundtruth.drop([\"attention\",\"user_id\"], axis=1)\n",
    "groundtruth.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>ad_position</th>\n",
       "      <th>ad_type</th>\n",
       "      <th>ad_category</th>\n",
       "      <th>serp_id</th>\n",
       "      <th>query</th>\n",
       "      <th>log_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHL</td>\n",
       "      <td>top-left</td>\n",
       "      <td>dd</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>tablets</td>\n",
       "      <td>tablets</td>\n",
       "      <td>20181002033126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VEN</td>\n",
       "      <td>top-right</td>\n",
       "      <td>dd</td>\n",
       "      <td>Shop - Luxury Goods</td>\n",
       "      <td>casio-watches</td>\n",
       "      <td>casio watches</td>\n",
       "      <td>20181001211223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEN</td>\n",
       "      <td>top-left</td>\n",
       "      <td>native</td>\n",
       "      <td>Shop - Luxury Goods</td>\n",
       "      <td>chivas-regal</td>\n",
       "      <td>chivas regal</td>\n",
       "      <td>20181001170952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country ad_position ad_type              ad_category        serp_id  \\\n",
       "0     PHL    top-left      dd  Computers & Electronics        tablets   \n",
       "1     VEN   top-right      dd      Shop - Luxury Goods  casio-watches   \n",
       "2     VEN    top-left  native      Shop - Luxury Goods   chivas-regal   \n",
       "\n",
       "           query          log_id  \n",
       "0        tablets  20181002033126  \n",
       "1  casio watches  20181001211223  \n",
       "2   chivas regal  20181001170952  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participants = pd.read_csv(\"participants.tsv\", delimiter=\"\\t\")\n",
    "participants = participants.drop([\"user_id\",\"education\",\"age\",\"income\",\"gender\"], axis=1)\n",
    "participants.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Merge two data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2909 entries, 0 to 2908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   country      2909 non-null   object\n",
      " 1   ad_position  2909 non-null   object\n",
      " 2   ad_type      2909 non-null   object\n",
      " 3   ad_category  2909 non-null   object\n",
      " 4   serp_id      2909 non-null   object\n",
      " 5   query        2909 non-null   object\n",
      " 6   log_id       2909 non-null   object\n",
      " 7   ad_clicked   2909 non-null   int64 \n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 181.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = participants.merge(groundtruth,on=\"log_id\")\n",
    "df[\"log_id\"] = df[\"log_id\"].astype(str)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns that have numercal types are =>['ad_clicked'] \n",
      "columns that have object types are =>['country', 'ad_position', 'ad_type', 'ad_category', 'serp_id', 'query', 'log_id']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Extract the column names with number type\n",
    "num_columns = df.select_dtypes(np.number).columns.to_list()\n",
    "\n",
    "# Extract the column names with object type\n",
    "object_columns = df.select_dtypes(object).columns.to_list()\n",
    "\n",
    "# print the result\n",
    "print(f'columns that have numercal types are =>{num_columns} \\n\\\n",
    "columns that have object types are =>{object_columns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Filter data frame based on time spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>ad_position</th>\n",
       "      <th>ad_type</th>\n",
       "      <th>ad_category</th>\n",
       "      <th>serp_id</th>\n",
       "      <th>query</th>\n",
       "      <th>log_id</th>\n",
       "      <th>ad_clicked</th>\n",
       "      <th>time_spent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHL</td>\n",
       "      <td>top-left</td>\n",
       "      <td>dd</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>tablets</td>\n",
       "      <td>tablets</td>\n",
       "      <td>20181002033126</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VEN</td>\n",
       "      <td>top-right</td>\n",
       "      <td>dd</td>\n",
       "      <td>Shop - Luxury Goods</td>\n",
       "      <td>casio-watches</td>\n",
       "      <td>casio watches</td>\n",
       "      <td>20181001211223</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEN</td>\n",
       "      <td>top-left</td>\n",
       "      <td>native</td>\n",
       "      <td>Shop - Luxury Goods</td>\n",
       "      <td>chivas-regal</td>\n",
       "      <td>chivas regal</td>\n",
       "      <td>20181001170952</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country ad_position ad_type              ad_category        serp_id  \\\n",
       "0     PHL    top-left      dd  Computers & Electronics        tablets   \n",
       "1     VEN   top-right      dd      Shop - Luxury Goods  casio-watches   \n",
       "2     VEN    top-left  native      Shop - Luxury Goods   chivas-regal   \n",
       "\n",
       "           query          log_id  ad_clicked  time_spent  \n",
       "0        tablets  20181002033126           0          96  \n",
       "1  casio watches  20181001211223           1          18  \n",
       "2   chivas regal  20181001170952           0          54  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "df[\"time_spent\"] = 0\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    file_path = f\"logs/{row['log_id']}.csv\"\n",
    "    if not os.path.exists(file_path):\n",
    "        continue\n",
    "    df2 = pd.read_csv(file_path, delimiter=\" \")\n",
    "    time_spent = df2[\"timestamp\"].iloc[-1] - df2[\"timestamp\"].iloc[0]\n",
    "    df.at[index,\"time_spent\"] = int(time_spent/1000)\n",
    "\n",
    "df = df[df[\"time_spent\"] > 5]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Convert categorical values to numeral values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lk/ytw1q78d13v3jdvbccylp_2r0000gn/T/ipykernel_6271/3537954151.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[cat_name] = df[cat_name].replace(names,nums)\n"
     ]
    }
   ],
   "source": [
    "categories = [\"query\",\"country\",\"ad_type\",\"ad_position\",\"ad_category\",\"serp_id\"]\n",
    "\n",
    "for cat_name in categories:\n",
    "    names = df[cat_name].unique()\n",
    "    nums =[i for i in range(len(names))]\n",
    "    df[cat_name] = df[cat_name].replace(names,nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_type\n",
      "0    1612\n",
      "1     806\n",
      "Name: count, dtype: int64\n",
      "------\n",
      "ad_position\n",
      "0    1640\n",
      "1     778\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count number of values under ad_type\n",
    "print(df['ad_type'].value_counts())\n",
    "print(\"------\")\n",
    "print(df['ad_position'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num of nulls</th>\n",
       "      <th>num of unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad_position</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad_type</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad_category</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serp_id</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_id</th>\n",
       "      <td>0</td>\n",
       "      <td>2418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad_clicked</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_spent</th>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             num of nulls  num of unique\n",
       "country                 0             68\n",
       "ad_position             0              2\n",
       "ad_type                 0              2\n",
       "ad_category             0             14\n",
       "serp_id                 0             63\n",
       "query                   0             55\n",
       "log_id                  0           2418\n",
       "ad_clicked              0              2\n",
       "time_spent              0            276"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of null values in each feature\n",
    "num_null_value = df.isnull().sum()\n",
    "\n",
    "# Determine the number of unique values in each feature\n",
    "num_unique_value = df.nunique()\n",
    "\n",
    "# Create a summary dataframe combining null and unique value counts\n",
    "df_summary = pd.concat([num_null_value,num_unique_value], axis='columns', keys= ['num of nulls', 'num of unique'])\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Extract xml data consisit document width and height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install beautifulsoup4\n",
    "# pip3 install lxml\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "df[\"doc_width\"] = 0\n",
    "df[\"doc_height\"] = 0\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    with open(f\"logs/{row['log_id']}.xml\", 'r') as f:\n",
    "        data = f.read()\n",
    "    doc_w, doc_h = BeautifulSoup(data, \"html.parser\").find(\"document\").text.split(\"x\")\n",
    "    scr_w, scr_h = BeautifulSoup(data, \"html.parser\").find(\"screen\").text.split(\"x\")\n",
    "    df.at[index,\"doc_width\"] = max(int(doc_w),int(scr_w))\n",
    "    df.at[index,\"doc_height\"] = max(int(doc_h),int(scr_h))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Extract log file information into matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "event = {\"click\":1,\"mouseup\":2,\"mouseover\":3,\"mousedown\":4,\"mousemove\":5}\n",
    "w = 3\n",
    "h = 3\n",
    "matrix1 = []\n",
    "matrix2 = []\n",
    "\n",
    "for index1,row1 in df.iterrows():\n",
    "\n",
    "    matrix_event = np.array([[0 for x in range(w)] for y in range(h)])\n",
    "    matrix_time = np.array([[0 for x in range(w)] for y in range(h)])\n",
    "\n",
    "    df2 = pd.read_csv(f\"logs/{row1['log_id']}.csv\", delimiter=\" \")\n",
    "    start_time = df2.at[0,\"timestamp\"]\n",
    "\n",
    "    for index, row in df2.iterrows():\n",
    "        xpos = (int(row[\"xpos\"])/row1[\"doc_width\"]) * w\n",
    "        xpos = min(w-1,int(xpos))\n",
    "\n",
    "        ypos = (int(row[\"ypos\"])/row1[\"doc_height\"]) * h\n",
    "        ypos = min(h-1,int(ypos))\n",
    "\n",
    "        matrix_event[xpos][ypos] = event.get(row[\"event\"]) or 0\n",
    "        matrix_time[xpos][ypos] = int((row[\"timestamp\"] - start_time)/1000)\n",
    "\n",
    "\n",
    "    matrix_event = matrix_event.flatten()\n",
    "    matrix1.append(matrix_event)\n",
    "\n",
    "    matrix_time = matrix_time.flatten()\n",
    "    matrix2.append(matrix_time)    \n",
    "\n",
    "matrix1 = pd.DataFrame(matrix1)\n",
    "matrix2 = pd.DataFrame(matrix2)\n",
    "\n",
    "matrix1 =  matrix1.astype(int)\n",
    "matrix2 =  matrix2.astype(int)\n",
    "\n",
    "dataset = pd.concat([df, matrix1, matrix2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset[\"ad_clicked\"]\n",
    "dataset = dataset.drop(\"ad_clicked\", axis=1)\n",
    "\n",
    "print(f'Shape of features data set for ML models => {dataset.shape}')\n",
    "print(f'Shape of target for ML models => {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create correlation matrix for features\n",
    "features = dataset[[\"country\",\"ad_position\",\"ad_type\",\"ad_category\",\"serp_id\",\"query\",\"time_spent\"]]\n",
    "feature_corr = features.corr(numeric_only=True)\n",
    "\n",
    "# Display correlation matrix\n",
    "display(feature_corr)\n",
    "\n",
    "# Plot correlation matrix\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(feature_corr, annot=True, fmt='0.2f', linewidths=0.5, linecolor='Black', cmap='Spectral')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainvald, X_test, y_trainvald, y_test = train_test_split(dataset, labels, test_size=0.20, random_state=42)\n",
    "X_train, X_vald, y_train, y_vald = train_test_split(X_trainvald, y_trainvald, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape\n",
    "dataset.to_string(\"text.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Create Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "input_tensor = layers.Input(shape=(2822,29, 3))\n",
    "\n",
    "################### Conv layer one #######################\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l1(0.01))(input_tensor)\n",
    "maxpool1 = layers.MaxPooling2D((2, 2))(conv1)\n",
    "dropout1 = layers.Dropout(0.25)(maxpool1)\n",
    "\n",
    "################### Conv layer two #######################\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l1(0.01))(dropout1)\n",
    "maxpool2 = layers.MaxPooling2D((2, 2))(conv2)\n",
    "dropout2 = layers.Dropout(0.25)(maxpool2)\n",
    "\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l1(0.01))(dropout2)\n",
    "maxpool3 = layers.MaxPooling2D((2, 2))(conv3)\n",
    "\n",
    "################### Convert tensors to vectors #######################\n",
    "flatten = layers.Flatten()(maxpool3)\n",
    "\n",
    "dense1 = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l1(0.01))(flatten)\n",
    "dropout3 = layers.Dropout(0.5)(dense1)\n",
    "\n",
    "n_classes = len(np.unique(labels)) \n",
    "output_tensor = layers.Dense(n_classes, activation='sigmoid')(dropout3)\n",
    "modeling = models.Model(inputs=input_tensor, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checking = ModelCheckpoint('my_model.keras', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "history = modeling.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_vald, y_vald), callbacks=[early_stop, checking])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## References\n",
    "\n",
    "- Keras API reference / Optimizers(https://keras.io/api/optimizers/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
